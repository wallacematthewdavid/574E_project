{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "import os\n",
        "\n",
        "# File paths\n",
        "input_file = 'wfigs_az.csv'\n",
        "intermediate_file = 'wfigs_az_with_weather_partial.csv'\n",
        "final_output_file = 'wfigs_az_with_weather_single_date.csv'\n",
        "\n",
        "# Load the CSV file\n",
        "if os.path.exists(intermediate_file):\n",
        "    print(f\"Resuming from partially saved file: {intermediate_file}\")\n",
        "    data = pd.read_csv(intermediate_file)\n",
        "else:\n",
        "    print(f\"Starting from the original file: {input_file}\")\n",
        "    data = pd.read_csv(input_file)\n",
        "    # Ensure proper date formatting\n",
        "    data['FireDiscoveryDateTime'] = pd.to_datetime(data['FireDiscoveryDateTime'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "    # Filter invalid latitude and longitude\n",
        "    data = data[(data['InitialLatitude'].between(-90, 90)) & (data['InitialLongitude'].between(-180, 180))]\n",
        "    # Add new columns for weather data\n",
        "    data['tmax'] = None\n",
        "    data['tmin'] = None\n",
        "    data['prcp'] = None\n",
        "\n",
        "# Function to fetch weather data from Daymet API for a specific date with retries\n",
        "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=1, max=10))\n",
        "def get_daymet_data(lat, lon, date, idx):\n",
        "    url = \"https://daymet.ornl.gov/single-pixel/api/data\"\n",
        "    params = {\n",
        "        'lat': lat,\n",
        "        'lon': lon,\n",
        "        'vars': 'tmax,tmin,prcp',  # Variables: max temp, min temp, and precipitation\n",
        "        'start': date,  # Start date\n",
        "        'end': date,    # End date (same as start date for a single day)\n",
        "        'format': 'json'\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params, timeout=10)  # Add timeout for the request\n",
        "\n",
        "    # If response is successful\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        # Check if the response contains data\n",
        "        if 'data' in data and len(data['data']) > 0:\n",
        "            record = data['data']\n",
        "            return {\n",
        "                'idx': idx,\n",
        "                'tmax': record.get(\"tmax (deg c)\", [None])[0],\n",
        "                'tmin': record.get(\"tmin (deg c)\", [None])[0],\n",
        "                'prcp': record.get(\"prcp (mm/day)\", [None])[0]\n",
        "            }\n",
        "        else:\n",
        "            return {'idx': idx, 'tmax': None, 'tmin': None, 'prcp': None}\n",
        "    else:\n",
        "        response.raise_for_status()\n",
        "\n",
        "# Concurrent request processing\n",
        "def process_rows_concurrently(data, intermediate_file, max_workers=10):\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        # Prepare rows to process (skip already completed rows)\n",
        "        rows_to_process = data[(data['tmax'].isnull()) | (data['tmin'].isnull()) | (data['prcp'].isnull())]\n",
        "        futures = {\n",
        "            executor.submit(get_daymet_data, row['InitialLatitude'], row['InitialLongitude'], row['FireDiscoveryDateTime'], idx): idx\n",
        "            for idx, row in rows_to_process.iterrows()\n",
        "        }\n",
        "\n",
        "        # Process futures as they complete\n",
        "        for i, future in enumerate(tqdm(as_completed(futures), total=len(futures), desc=\"Processing rows\")):\n",
        "            try:\n",
        "                result = future.result()\n",
        "                if result:\n",
        "                    idx = result['idx']\n",
        "                    data.at[idx, 'tmax'] = result['tmax']\n",
        "                    data.at[idx, 'tmin'] = result['tmin']\n",
        "                    data.at[idx, 'prcp'] = result['prcp']\n",
        "            except Exception as e:\n",
        "                print(f\"Exception: {e}\")\n",
        "\n",
        "            # Save intermediate progress every 100 rows\n",
        "            if i % 100 == 0:\n",
        "                data.to_csv(intermediate_file, index=False)\n",
        "                print(f\"Intermediate progress saved to {intermediate_file}\")\n",
        "\n",
        "        # Final save after processing all rows\n",
        "        data.to_csv(intermediate_file, index=False)\n",
        "        print(f\"All intermediate progress saved to {intermediate_file}\")\n",
        "\n",
        "# Run the processing\n",
        "process_rows_concurrently(data, intermediate_file)\n",
        "\n",
        "# Final save\n",
        "data.to_csv(final_output_file, index=False)\n",
        "print(f\"Final results saved to {final_output_file}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lwWLqjO53V3",
        "outputId": "e3d0ee29-472a-428c-b89e-85a81cd8a038"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming from partially saved file: wfigs_az_with_weather_partial.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-a3acd9a58052>:16: DtypeWarning: Columns (14,20,21,23,32,46,68,69,77,78,90,91,94) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(intermediate_file)\n",
            "Processing rows:   0%|          | 0/17 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception: RetryError[<Future at 0x7d196e8d2950 state=finished raised HTTPError>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing rows:   6%|▌         | 1/17 [00:25<06:46, 25.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intermediate progress saved to wfigs_az_with_weather_partial.csv\n",
            "Exception: RetryError[<Future at 0x7d195ed08e20 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d18a8f2afb0 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d18a8e164a0 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d18a9012530 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d195ed09540 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d195eeee200 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d191cb1f970 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d195ed74910 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d191cb1ff70 state=finished raised HTTPError>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing rows:  82%|████████▏ | 14/17 [00:45<00:07,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception: RetryError[<Future at 0x7d196e834fa0 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d18a8fadcf0 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d196e837130 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d196e835c60 state=finished raised HTTPError>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing rows: 100%|██████████| 17/17 [00:45<00:00,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception: RetryError[<Future at 0x7d196e837b50 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d18a8f29930 state=finished raised HTTPError>]\n",
            "Exception: RetryError[<Future at 0x7d195ed96a40 state=finished raised HTTPError>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All intermediate progress saved to wfigs_az_with_weather_partial.csv\n",
            "Final results saved to wfigs_az_with_weather_single_date.csv.\n"
          ]
        }
      ]
    }
  ]
}